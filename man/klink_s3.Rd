% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/klink_s3.R
\name{klink_s3}
\alias{klink_s3}
\title{Kellogg S3 (kortex) connection}
\usage{
klink_s3(region = 'kna', ignore_existing = FALSE)
}
\arguments{
\item{region}{Character string representing the regional bucket you need to connect to. Current options are 'globa', 'kna', 'keu', 'kla', and 'kamea'. Default is 'kna' in order to avoid breaking code written using previous versions.}

\item{ignore_existing}{Logical indicating whether to ignore existing connections when executing function. Setting to TRUE can cause warnings/errors but may be useful if you want to flush your connection.}
}
\value{
populates user environment with required role and settings to access the corresponding S3 environment
}
\description{
Defines system environment variables required to utilize aws.s3 functions and returns paws s3 connection by way of iam role assumption.

In order to use these tools users must first:
\enumerate{
\item Have a RStudio Connect account (you likely have one already if you're using RStudio Workbench, if not you can request access through Digital Concierge).
\item Create a local RStudio Connect API key \url{https://docs.rstudio.com/connect/user/api-keys}
\item Create an .Renviron file in your Home folder assigning your API key value to the name "CONNECT_API_KEY" \url{https://rstats.wtf/r-startup.html}
}

Note: the klink_s3() function currently only works from within our RStudio server environment
}
\examples{
# Retrieve required system settings (in background) and appropriate s3 bucket name
klink_s3()

# Use example aws.s3 functions to retrieve information from s3 bucket
# (making sure to reference the bucket as "s3BucketName")

aws.s3::get_bucket_df(region = 'kna', s3BucketName, max = 20)[["Key"]]

s3_other$list_objects(Bucket = s3BucketName)
}
